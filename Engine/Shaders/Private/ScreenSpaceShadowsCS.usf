#include "SceneTextureParameters.ush"


float4 LightPositionOrDirection; // xyzw = (position.xyz, 1/radius)
RWTexture2D<float2> RWShadowFactors;
RWTexture2D<float2> testFactors;

#define THREADGROUP_SIZEX 8
#define THREADGROUP_SIZEY 8
#define DownsampleFactor 2




[numthreads(8, 8, 1)]
void Main_CS(
    uint3 GroupId : SV_GroupID,  // 线程组ID，全局
	uint3 DispatchThreadId : SV_DispatchThreadID,    // 全局线程ID
    uint3 GroupThreadId : SV_GroupThreadID			// 线程组内的局部线程ID
)
{
	int NumSteps = 64; 
	float Thickness = 0.02;
	float ShadowIntensity = 0.1;
	float CompareTorelanceScale = 2.0;

	uint ThreadIndex = GroupThreadId.y * THREADGROUP_SIZEX + GroupThreadId.x;  // 局部线程索引
	float2 ScreenUV = (DispatchThreadId.xy + View.ViewRectMin.xy + .5f) * View.BufferSizeAndInvSize.zw;  // 范围：[0,1]
	float2 ScreenPosition = (ScreenUV - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy;  // [0, 1]的UV坐标转为[-1,1](OpenGL)或者[0,1]*[-1,1](DirectX)的NDC坐标，
																											// 在OpenGL中，View.ScreenPositionScaleBias的值可能为(0.5,-0.5,0.5,0.5)，平移+缩放

	FGBufferData GBuffer = GetGBufferDataFromSceneTextures(ScreenUV);
	const float3 N = GBuffer.WorldNormal;
	const float SceneDepth = GBuffer.Depth;  // 距离相机最近的屏幕深度值

	float4 PositionTranslatedWorld = mul(            // "TranslatedWorld"是UE的坐标系（世界空间减去相机相对原点），计算像素实际的深度值（世界）
		float4(ScreenPosition * SceneDepth, SceneDepth, 1),     
		View.ScreenToTranslatedWorld
	);

	float4 test = mul(float4(0, 0, PositionTranslatedWorld.z, 1.0), View.TranslatedWorldToClip);
	RWShadowFactors[DispatchThreadId.xy] = float2(test.z, test.w);
	RWShadowFactors[DispatchThreadId.xy] = float2(0, 1);

	const float Dither = InterleavedGradientNoise(DispatchThreadId.xy + 0.5f, View.StateFrameIndexMod8);

	

	//float4 startClipPos = mul(PositionTranslatedWorld, View.TranslatedWorldToClip);
	//float2 startScreenPos = (startClipPos.xy * rcp(startClipPos.w) ) * float2(0.5, -0.5) + 0.5;
	//OutColor = float4(startScreenPos.xy, 0, 1);

	// view dir
	const float3 V = normalize((View.TranslatedWorldCameraOrigin - PositionTranslatedWorld).xyz);

	// light direction
	const float3 LightDirection = -LightPositionOrDirection.xyz;

	// skip back ray
	float NdotL = dot(N, LightDirection);
	//if (NdotL <= 0.0) {
 	//	RWShadowFactors[DispatchThreadId.xy] = float2(0, 0);
	//	return ;
	//}

	// parameters
	float stepSize = 10; // 后续要调整
	float4 rayStep = float4(LightDirection * stepSize, 0);

	// modify position to avoid self-intersection
	float4 currentTranslateWorldPos = PositionTranslatedWorld + float4(N, 0) * Thickness;

	// ray tracing
	float shadow = 1.0;

	// 把世界空间的深度比较改为NDC的深度比较
	float contactShadowLength = 1.0;
	float2 TanViewFOV = GetTanHalfFieldOfView();
	float contactShadowLengthScreenScale = (TanViewFOV.y * SceneDepth);
	float RayLength = contactShadowLengthScreenScale * contactShadowLength;


	float4 startClip = mul(PositionTranslatedWorld, View.TranslatedWorldToClip);
	float4 dirClip = mul(float4(LightDirection * RayLength, 0), View.TranslatedWorldToClip);
	float4 endClip = startClip + dirClip;

	float3 startScreen = startClip.xyz / startClip.w; // 这里应该可以直接用最开始计算出来的ScreenPosition
	float3 endScreen = endClip.xyz / endClip.w;
	float3 stepScreen = endScreen - startScreen; 

	float3 startUVZ = float3(startScreen.xy * View.ScreenPositionScaleBias.xy + View.ScreenPositionScaleBias.wz, startScreen.z); //  这里前两个维度应该可以用ScreenUV
	float3 stepUVZ = float3(stepScreen.xy * View.ScreenPositionScaleBias.xy, stepScreen.z);

	float4 depthClip = startClip + mul(float4(0, 0, RayLength, 0), View.ViewToClip);
	float3 depthScreen = depthClip.xyz / depthClip.w;


	const float stepOffset = Dither - 0.5f;
	float step = 1.0 / NumSteps;
	float sampleTime = stepOffset * step + step;
	//sampleTime = 0.078;

	const float CompareTolerance = abs(depthScreen.z - startScreen.z) * step * CompareTorelanceScale;

	RWShadowFactors[DispatchThreadId.xy] = float2(1.0, SceneDepth);

	testFactors[DispatchThreadId.xy] = float2(0, 0);

	for (int i = 0; i < NumSteps; i++)
	{
		float3 sampleUVZ = startUVZ + stepUVZ * sampleTime;
		FGBufferData currentGBuffer = GetGBufferDataFromSceneTextures(sampleUVZ.xy);
		float sampleDepthWorld = currentGBuffer.Depth; // 这里的depth应该是Translated世界空间的

		float sampleDepth = ConvertToDeviceZ(sampleDepthWorld);


		float depthDiff = sampleUVZ.z - sampleDepth;
		bool selfOcclusion = abs(startUVZ.z - sampleDepth) < 1e-5;
		bool Hit = abs(depthDiff + CompareTolerance) < CompareTolerance && !selfOcclusion;


		if (abs(DispatchThreadId.x - 233) < 0.01 && abs(DispatchThreadId.y - 250) <  0.01) {
			testFactors[DispatchThreadId.xy] = float2(1.0, 0.0);
			// (DispatchThreadId.xy + View.ViewRectMin.xy + .5f) * View.BufferSizeAndInvSize.zw;
			float2 samplePixel = (sampleUVZ.xy * View.BufferSizeAndInvSize.xy) - 0.5 - View.ViewRectMin.xy;
			uint2 samplePixelInt = uint2(samplePixel);
			testFactors[samplePixelInt] = float2(1.0, 0.0);
		}


		if (Hit && all(0.0 < sampleUVZ.xy && sampleUVZ.xy < 1.0)) {
			RWShadowFactors[DispatchThreadId.xy] = float2(0.0, SceneDepth);
			return ;
		}

		

		sampleTime += (1.0 / NumSteps);
		
	}
	return ;
}

